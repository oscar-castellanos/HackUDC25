services:
  backend:
    build: clothing_compare
    ports:
      - "8000:8000"
    volumes:
      - ./clothing_compare:/app
    env_file:
      ".apikeys.env"
  frontend:
    build: 
      context: frontend
      dockerfile: Dockerfile.front.dev
    ports:
      - "8080:8080"
    volumes:
      - ./frontend/src:/app/src
  ollama:
    image: ollama/ollama:latest
    # Expose ollama port for debugging
    ports:
      - "11434:11434"
    volumes:
      - ./model_data/ollama:/root/.ollama
    restart: unless-stopped
    post_start:
      - command: ["sh", "-c", "ollama pull llama3.2:3b && ollama pull llava:7b"]
    # Enable GPU support
    # deploy:
    #       resources:
    #         reservations:
    #           devices:
    #             - driver: nvidia
    #               count: 1
    #               capabilities: [gpu]